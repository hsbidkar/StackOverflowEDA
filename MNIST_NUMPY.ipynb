{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_NUMPY.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMGelplHvReuPNGFOBccxCw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsbidkar/StackOverflowEDA/blob/main/MNIST_NUMPY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOcTvEK9aHlo"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import gzip\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import h5py\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEZM74vdd2LG"
      },
      "source": [
        "# Load the data:\n",
        "def load_data():\n",
        "    f = gzip.open('mnist.pkl.gz', 'rb')\n",
        "    f.seek(0)\n",
        "    training_data, validation_data, test_data = pickle.load(f,encoding='latin1')\n",
        "    f.close()\n",
        "    return (training_data, validation_data, test_data)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wX7OzlXd9tr",
        "outputId": "27235969-e110-4419-b9b0-502deb9382db"
      },
      "source": [
        "# Load the data into training_data, validation_data and test_data arrays:\n",
        "training_data, validation_data, test_data = load_data()\n",
        "training_data"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              " array([5, 0, 4, ..., 8, 4, 8]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tm1FOZWCe-bA",
        "outputId": "1027c6d2-2cb5-403f-e796-029d2f2e7a12"
      },
      "source": [
        "# Check the shape of data:\n",
        "print(training_data[0].shape)\n",
        "print(training_data[1].shape)\n",
        "\n",
        "# Take a look at the feature and target dataset:\n",
        "print(\"The feature dataset is:\" + \"\\n\" + str(training_data[0]))\n",
        "print(\"\\nThe target dataset is:\" + \"\\n\" + str(training_data[1]))\n",
        " \n",
        "# Take a look at the length of training data:\n",
        "print(\"\\nThe number of examples in the training dataset is:\" + str(len(training_data[0])))\n",
        " \n",
        "# Take a look at number of datapoints in each input:\n",
        "print(\"\\nThe number of points in a single input is:\" + str(len(training_data[0][1])))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 784)\n",
            "(50000,)\n",
            "The feature dataset is:\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "The target dataset is:\n",
            "[5 0 4 ... 8 4 8]\n",
            "\n",
            "The number of examples in the training dataset is:50000\n",
            "\n",
            "The number of points in a single input is:784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aewH2MB4fHYA",
        "outputId": "ba14eca2-4a29-47bb-9609-0218212faf44"
      },
      "source": [
        "def one_hot(j):\n",
        "# input is the target dataset of shape (m,) where m is the number of data points\n",
        "# returns a 2 dimensional array of shape (10, m) where each target value is converted to a one hot encoding\n",
        "    n = j.shape[0]\n",
        "    new_array = np.zeros((10, n))\n",
        "    index = 0\n",
        "    for res in j:\n",
        "        new_array[res][index] = 1.0\n",
        "        index = index + 1\n",
        "    return new_array\n",
        " \n",
        "data = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "print(data.shape)\n",
        "one_hot(data)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdQG1UI5geXm"
      },
      "source": [
        "def data_wrapper():\n",
        "    tr_d, va_d, te_d = load_data()\n",
        "    \n",
        "# Training data:\n",
        "    training_inputs = np.array(tr_d[0][:]).T\n",
        "    training_results = np.array(tr_d[1][:])\n",
        "    train_set_y = one_hot(training_results)\n",
        "    \n",
        "# Validation data:\n",
        "    validation_inputs = np.array(va_d[0][:]).T\n",
        "    validation_results = np.array(va_d[1][:])\n",
        "    validation_set_y = one_hot(validation_results)\n",
        "    \n",
        "# Test data:\n",
        "    test_inputs = np.array(te_d[0][:]).T\n",
        "    test_results = np.array(te_d[1][:])\n",
        "    test_set_y = one_hot(test_results)\n",
        "    \n",
        "    return (training_inputs, train_set_y, test_inputs, test_set_y)\n",
        "\n",
        "train_set_x, train_set_y, test_set_x, test_set_y = data_wrapper()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIViofxPgiVZ",
        "outputId": "3e12c8b5-3440-4c67-ecd1-85254525b53f"
      },
      "source": [
        "# Print shapes of the encoded data:\n",
        "print (\"train_set_x shape: \" + str(train_set_x.shape))\n",
        "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
        "print (\"test_set_x shape: \" + str(test_set_x.shape))\n",
        "print (\"test_set_y shape: \" + str(test_set_y.shape))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_set_x shape: (784, 50000)\n",
            "train_set_y shape: (10, 50000)\n",
            "test_set_x shape: (784, 10000)\n",
            "test_set_y shape: (10, 10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "E75ooVI6grC1",
        "outputId": "987a8cc7-e0f4-4120-c2b6-1e570b16df2e"
      },
      "source": [
        "# Convert the encoded data to a dataframe and visualise it:\n",
        "y = pd.DataFrame(train_set_y)\n",
        "print(\"The target dataset is:\" + str(training_data[1]))\n",
        "print(\"The one hot encoding dataset is:\")\n",
        "y"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The target dataset is:[5 0 4 ... 8 4 8]\n",
            "The one hot encoding dataset is:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>49960</th>\n",
              "      <th>49961</th>\n",
              "      <th>49962</th>\n",
              "      <th>49963</th>\n",
              "      <th>49964</th>\n",
              "      <th>49965</th>\n",
              "      <th>49966</th>\n",
              "      <th>49967</th>\n",
              "      <th>49968</th>\n",
              "      <th>49969</th>\n",
              "      <th>49970</th>\n",
              "      <th>49971</th>\n",
              "      <th>49972</th>\n",
              "      <th>49973</th>\n",
              "      <th>49974</th>\n",
              "      <th>49975</th>\n",
              "      <th>49976</th>\n",
              "      <th>49977</th>\n",
              "      <th>49978</th>\n",
              "      <th>49979</th>\n",
              "      <th>49980</th>\n",
              "      <th>49981</th>\n",
              "      <th>49982</th>\n",
              "      <th>49983</th>\n",
              "      <th>49984</th>\n",
              "      <th>49985</th>\n",
              "      <th>49986</th>\n",
              "      <th>49987</th>\n",
              "      <th>49988</th>\n",
              "      <th>49989</th>\n",
              "      <th>49990</th>\n",
              "      <th>49991</th>\n",
              "      <th>49992</th>\n",
              "      <th>49993</th>\n",
              "      <th>49994</th>\n",
              "      <th>49995</th>\n",
              "      <th>49996</th>\n",
              "      <th>49997</th>\n",
              "      <th>49998</th>\n",
              "      <th>49999</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 50000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0      1      2      3      4      ...  49995  49996  49997  49998  49999\n",
              "0    0.0    1.0    0.0    0.0    0.0  ...    0.0    1.0    0.0    0.0    0.0\n",
              "1    0.0    0.0    0.0    1.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
              "2    0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
              "3    0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
              "4    0.0    0.0    1.0    0.0    0.0  ...    0.0    0.0    0.0    1.0    0.0\n",
              "5    1.0    0.0    0.0    0.0    0.0  ...    1.0    0.0    0.0    0.0    0.0\n",
              "6    0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
              "7    0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
              "8    0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    1.0    0.0    1.0\n",
              "9    0.0    0.0    0.0    0.0    1.0  ...    0.0    0.0    0.0    0.0    0.0\n",
              "\n",
              "[10 rows x 50000 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "A4a4T2ptg8IT",
        "outputId": "08901ba0-e8f2-4e17-91f9-eeeae32c3468"
      },
      "source": [
        "# Visualise a certain image from the training set:\n",
        "index  = 100\n",
        "k = train_set_x[:,index]\n",
        "k = k.reshape((28, 28))\n",
        "plt.title('Label is {label}'.format(label= training_data[1][index]))\n",
        "plt.imshow(k, cmap='gray')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fcdd81949d0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4ujoxaKiRMC"
      },
      "source": [
        "def sigmoid(Z):   \n",
        "# Z is NumPy array of shape (n, m) where n is the number of neurons in the layer and m is the number of samples\n",
        "    H = 1/(1+np.exp(-Z))\n",
        "    sigmoid_memory = Z\n",
        "\n",
        "# sigmoid_memory is stored as it is used later on in backpropagation \n",
        "    return H, sigmoid_memory"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89SJzRQHjefu",
        "outputId": "2783f28d-6062-4bb8-ec7a-58a2e4f482dc"
      },
      "source": [
        "Z = np.arange(-8,8).reshape(8,2)\n",
        "print(\"sigmoid(Z) = \\n\" + str(sigmoid(Z)))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sigmoid(Z) = \n",
            "(array([[3.35350130e-04, 9.11051194e-04],\n",
            "       [2.47262316e-03, 6.69285092e-03],\n",
            "       [1.79862100e-02, 4.74258732e-02],\n",
            "       [1.19202922e-01, 2.68941421e-01],\n",
            "       [5.00000000e-01, 7.31058579e-01],\n",
            "       [8.80797078e-01, 9.52574127e-01],\n",
            "       [9.82013790e-01, 9.93307149e-01],\n",
            "       [9.97527377e-01, 9.99088949e-01]]), array([[-8, -7],\n",
            "       [-6, -5],\n",
            "       [-4, -3],\n",
            "       [-2, -1],\n",
            "       [ 0,  1],\n",
            "       [ 2,  3],\n",
            "       [ 4,  5],\n",
            "       [ 6,  7]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltI2vloqjyT0"
      },
      "source": [
        "def relu(Z):\n",
        "# Z is NumPy array of shape (n, m) where n is the number of neurons in the layer and m is the number of samples \n",
        "    H = np.maximum(0,Z)\n",
        "    \n",
        "    assert(H.shape == Z.shape)\n",
        "    \n",
        "    relu_memory = Z \n",
        "\n",
        "# relu_memory is stored as it is used later on in backpropagation\n",
        "    return H, relu_memory"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZcYXm06kB3T",
        "outputId": "99e04c50-7a85-4088-cc83-967d1c5bc6b8"
      },
      "source": [
        "Z = np.array([1, 3, -1, -4, -5, 7, 9, 18]).reshape(4,2)\n",
        "print (\"relu(Z) = \" + str(relu(Z)))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "relu(Z) = (array([[ 1,  3],\n",
            "       [ 0,  0],\n",
            "       [ 0,  7],\n",
            "       [ 9, 18]]), array([[ 1,  3],\n",
            "       [-1, -4],\n",
            "       [-5,  7],\n",
            "       [ 9, 18]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBoo3n_zkzLA"
      },
      "source": [
        "def softmax(Z):\n",
        "# Z is NumPy array of shape (n, m) where n is the number of neurons in the layer and m is the number of samples \n",
        "    Z_exp = np.exp(Z)\n",
        " \n",
        "    Z_sum = np.sum(Z_exp,axis = 0, keepdims = True)\n",
        "    \n",
        "    H = Z_exp/Z_sum  #normalising step\n",
        "    softmax_memory = Z\n",
        "\n",
        "# softmax_memory is stored as it is used later on in backpropagation\n",
        "    return H, softmax_memory"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9vmqHz_lHyq",
        "outputId": "7e5980b7-9d2f-4c72-da41-8b48aa663fe2"
      },
      "source": [
        "Z = np.array(np.arange(30)).reshape(10,3)\n",
        "H, softmax_memory = softmax(Z)\n",
        "print(H)\n",
        "\n",
        "print(softmax_memory)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.78595259e-12 1.78595259e-12 1.78595259e-12]\n",
            " [3.58718166e-11 3.58718166e-11 3.58718166e-11]\n",
            " [7.20504697e-10 7.20504697e-10 7.20504697e-10]\n",
            " [1.44717237e-08 1.44717237e-08 1.44717237e-08]\n",
            " [2.90672341e-07 2.90672341e-07 2.90672341e-07]\n",
            " [5.83831003e-06 5.83831003e-06 5.83831003e-06]\n",
            " [1.17265592e-04 1.17265592e-04 1.17265592e-04]\n",
            " [2.35534237e-03 2.35534237e-03 2.35534237e-03]\n",
            " [4.73083162e-02 4.73083162e-02 4.73083162e-02]\n",
            " [9.50212932e-01 9.50212932e-01 9.50212932e-01]]\n",
            "[[ 0  1  2]\n",
            " [ 3  4  5]\n",
            " [ 6  7  8]\n",
            " [ 9 10 11]\n",
            " [12 13 14]\n",
            " [15 16 17]\n",
            " [18 19 20]\n",
            " [21 22 23]\n",
            " [24 25 26]\n",
            " [27 28 29]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NzTjgv6lddP"
      },
      "source": [
        "def initialize_parameters(dimensions):\n",
        "# dimensions is a list containing the number of neuron in each layer in the network\n",
        "# It returns parameters which is a python dictionary containing the parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
        "    np.random.seed(7)\n",
        "    parameters = {}\n",
        "    L = len(dimensions)            # number of layers in the network + 1\n",
        " \n",
        "    for l in range(1, L): \n",
        "        parameters['W'+str(l)]=np.random.randn(dimensions[l],dimensions[l-1])*0.1\n",
        "        parameters['b' + str(l)]=np.zeros((dimensions[l], 1)) \n",
        "        \n",
        "        assert(parameters['W' + str(l)].shape==(dimensions[l],dimensions[l-1]))\n",
        "        assert(parameters['b' + str(l)].shape == (dimensions[l], 1))\n",
        "        \n",
        "    return parameters"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaDWbSH5ljeX",
        "outputId": "182fd96b-5639-42d6-d0d7-325edec1c7e7"
      },
      "source": [
        "# Declare the dimensions:\n",
        "dimensions  = [784, 3, 7, 10]\n",
        " \n",
        "# Run the initialize_parameters() function:\n",
        "parameters = initialize_parameters(dimensions)\n",
        " \n",
        "# Print the resultant weights and biases:\n",
        "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
        "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
        "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
        "print(\"b2 = \" + str(parameters[\"b2\"]))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1 = [[-0.04167578 -0.00562668 -0.21361961 ... -0.06168445  0.03213358\n",
            "  -0.09464469]\n",
            " [-0.05301394 -0.1259207   0.16775441 ... -0.03284246 -0.05623108\n",
            "   0.01179136]\n",
            " [ 0.07386378 -0.15872956  0.01532001 ... -0.08428557  0.10040469\n",
            "   0.00545832]]\n",
            "b1 = [[0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "W2 = [[ 0.06650944 -0.19626047  0.2112715 ]\n",
            " [-0.28074571 -0.13967752  0.02641189]\n",
            " [ 0.10925169  0.06646016  0.08565535]\n",
            " [-0.11058228  0.03715795  0.13440124]\n",
            " [-0.16421272 -0.1153127   0.02013163]\n",
            " [ 0.13985659  0.07228733 -0.10717236]\n",
            " [-0.05673344 -0.03663499 -0.15460347]]\n",
            "b2 = [[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD0IczkqnAlM"
      },
      "source": [
        "def layer_forward(H_prev, W, b, activation = 'relu'):\n",
        " \n",
        "# H_prev is of shape (size of previous layer, number of examples)\n",
        "# W is weights matrix of shape (size of current layer, size of the previous layer)\n",
        "# b is bias vector of shape (size of the current layer, 1)\n",
        "# activation is the activation to be used for forward propagation: \"softmax\", \"relu\", \"sigmoid\".\n",
        "    \n",
        "    if activation == \"sigmoid\":\n",
        "        Z = np.dot(W, H_prev) + b \n",
        "        linear_memory = (H_prev, W, b)\n",
        "        H , activation_memory = sigmoid(Z)\n",
        " \n",
        "    elif activation == \"softmax\":\n",
        "        Z = np.dot(W, H_prev) + b \n",
        "        linear_memory = (H_prev, W, b)\n",
        "        H, activation_memory = softmax(Z)\n",
        "    \n",
        "    elif activation == \"relu\":\n",
        "        Z = np.dot(W, H_prev) + b\n",
        "        linear_memory = (H_prev, W, b)\n",
        "        H, activation_memory = relu(Z)\n",
        " \n",
        "# H is the output of the activation function \n",
        "# memory is a python dictionary containing \"linear_memory\" and \"activation_memory\"\n",
        "        \n",
        "    assert (H.shape == (W.shape[0], H_prev.shape[1]))\n",
        "    memory = (linear_memory, activation_memory)\n",
        " \n",
        "    return H, memory"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqFAxIyOnC56",
        "outputId": "7e787a1c-fe46-4aba-9681-4cbe392f8a47"
      },
      "source": [
        "# l-1 has two neurons, l has three, m = 5\n",
        "# H_prev is (l-1, m)\n",
        "# W is (l, l-1)\n",
        "# b is (l, 1)\n",
        "# H should be (l, m)\n",
        "H_prev = np.array([[1,0, 5, 10, 2], [2, 5, 3, 10, 2]])\n",
        "W_sample = np.array([[10, 5], [2, 0], [1, 0]])\n",
        "b_sample = np.array([10, 5, 0]).reshape((3, 1))\n",
        " \n",
        "H = layer_forward(H_prev, W_sample, b_sample, activation=\"sigmoid\")[0]\n",
        "H"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 1.        , 1.        , 1.        , 1.        ],\n",
              "       [0.99908895, 0.99330715, 0.99999969, 1.        , 0.99987661],\n",
              "       [0.73105858, 0.5       , 0.99330715, 0.9999546 , 0.88079708]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEvrZQoRn91r"
      },
      "source": [
        "def L_layer_forward(X, parameters):\n",
        "# X is input data of shape (input size, number of examples)\n",
        "# parameters is output of initialize_parameters()\n",
        " \n",
        "# memories is the list of memory containing(for a relu activation, for example):\n",
        "# - every memory of relu forward (there are L-1 of them, indexed from 1 to L-1), \n",
        "# - the memory of softmax forward (there is one, indexed L) \n",
        " \n",
        "    memories = []\n",
        "    H = X\n",
        "    L = len(parameters) // 2        # number of layers in the neural network\n",
        "    \n",
        "# Implement relu layer (L-1) times as the Lth layer is the softmax layer\n",
        "    for l in range(1, L):\n",
        "        H_prev = H \n",
        "        \n",
        "        H, memory = layer_forward(H_prev, \n",
        "                                 parameters[\"W\" + str(l)], \n",
        "                                 parameters[\"b\" + str(l)], \n",
        "                                 activation='relu')\n",
        "        memories.append(memory)\n",
        "    \n",
        "    # Implement the final softmax layer\n",
        "    # HL here is the final prediction P as specified in the lectures\n",
        "    HL, memory = layer_forward(H,\n",
        "                              parameters[\"W\" + str(L)], \n",
        "                              parameters[\"b\" + str(L)], \n",
        "                              activation='softmax')\n",
        "    memories.append(memory)\n",
        " \n",
        "    assert(HL.shape == (10, X.shape[1]))\n",
        "            \n",
        "    return HL, memories"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybI-Lf7Gn_4_",
        "outputId": "2d265ffa-98c0-44a6-818b-87348d93bd21"
      },
      "source": [
        "# X is (784, 10)\n",
        "# parameters is a dictionary\n",
        "# HL should be (10, 10)\n",
        "x_sample = train_set_x[:, 10:20]\n",
        "print(x_sample.shape)\n",
        "HL = L_layer_forward(x_sample, parameters=parameters)[0]\n",
        "print(HL[:, :5])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784, 10)\n",
            "[[0.10106734 0.10045152 0.09927757 0.10216656 0.1       ]\n",
            " [0.10567625 0.10230873 0.10170271 0.11250099 0.1       ]\n",
            " [0.09824287 0.0992886  0.09967128 0.09609693 0.1       ]\n",
            " [0.10028288 0.10013048 0.09998149 0.10046076 0.1       ]\n",
            " [0.09883601 0.09953443 0.09931419 0.097355   0.1       ]\n",
            " [0.10668575 0.10270912 0.10180736 0.11483609 0.1       ]\n",
            " [0.09832513 0.09932275 0.09954792 0.09627089 0.1       ]\n",
            " [0.09747092 0.09896735 0.0995387  0.09447277 0.1       ]\n",
            " [0.09489069 0.09788255 0.09929998 0.08915178 0.1       ]\n",
            " [0.09852217 0.09940447 0.09985881 0.09668824 0.1       ]]\n"
          ]
        }
      ]
    }
  ]
}